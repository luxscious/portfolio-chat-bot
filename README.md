# ğŸ¤– Gabriellaâ€™s Resume Chatbot

A personalized, first-person chatbot that answers questions based on my resume, work experience, skills, hobbies, and overall personality. Built with React + Vite, a Go backend, OpenAI, Neo4j for structured querying, and Ollama for intent parsing.

---

## ğŸ§  What It Does

- Embeds my structured resume data for retrieval (no raw text scraping)
- Uses Ollama (LLaMA3) to identify **target node types** and **filters**
- Runs Cypher queries on Neo4j to build **context**
- Builds prompts in my voice using `personaContext`
- Sends to OpenAI (GPT-3.5-Turbo)
- Returns chat responses that feel personal and natural
- Stores conversation history per user via MongoDB

---

## ğŸ§± Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  React Frontend (Vite)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Go Backend (API Server)  â”‚
â”‚                            â”‚
â”‚ 1. Accepts input           â”‚
â”‚ 2. Plans query via Ollama  â”‚
â”‚ 3. Retrieves data via Neo4jâ”‚
â”‚ 4. Builds context prompt   â”‚
â”‚ 5. Calls OpenAI            â”‚
â”‚ 6. Stores message in Mongo â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚   Ollama API   â”‚
     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚   Neo4j DB     â”‚
     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚  OpenAI GPT    â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  React: renders reply      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ” Key Features

- **Graph-Powered Prompting**: Semantic plans via Ollama â†’ structured context from Neo4j
- **Persona-Aware**: All responses are written in my own tone with first-person voice
- **Mongo-Backed Memory**: Conversation stored per-user for persistence
- **Small Talk Handling**: Recognizes vague input like â€œhi!â€ and skips AI calls

---

## ğŸ“ File Structure

```
portfolio-chat-bot/
â”œâ”€â”€ client/              # React + Vite frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/  # UI + chat components
â”‚   â”‚   â”œâ”€â”€ hooks/       # TypingEffect.ts etc.
â”‚   â”‚   â”œâ”€â”€ lib/         # Utility functions
â”‚   â”‚   â”œâ”€â”€ pages/       # ChatPage, App.tsx
â”‚   â”‚   â””â”€â”€ styles/      # Tailwind + custom CSS
â”œâ”€â”€ server/              # Go backend
â”‚   â”œâ”€â”€ config/          # .env loading
â”‚   â”œâ”€â”€ db/              # Neo4j + Mongo logic
â”‚   â”œâ”€â”€ openai/          # GPT + SmartQuery logic
â”‚   â”œâ”€â”€ ollama/          # Intent planning via LLaMA3
â”‚   â”œâ”€â”€ resume/          # resume.json and chunking
â”‚   â”œâ”€â”€ main.go          # Route binding
â”‚   â””â”€â”€ routes.go        # Route definitions
```

---

## âš™ï¸ Running the Project

### 1. Clone the repo

```bash
git clone https://github.com/luxscious/portfolio-chat-bot.git
cd portfolio-chat-bot
```

### 2. Set up env files

```bash
cp client/.env.example client/.env
cp server/.env.example server/.env
```

Then update:

```env
# OpenAI
OPENAI_API_KEY=sk-...
OPENAI_API_URL=https://api.openai.com/v1/chat/completions
OPENAI_EMBEDDING_URL=https://api.openai.com/v1/embeddings
OPENAI_THREAD_URL=https://api.openai.com/v1/threads
OPENAI_ASSISTANT_ID=

# Ollama
OLLAMA_URI=http://localhost:11434

# Server config
PORT=8080
FRONTEND_ORIGIN=http://localhost:5173

# MongoDB
MONGO_URI=mongodb://localhost:27017
MONGO_DB=resumeChatbot
MONGO_COLLECTION=messages

# Neo4j
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASS=password
```

### 3. Install frontend dependencies

```bash
cd client && npm install && npm run dev
```

### 4. Run backend (Go)

```bash
cd ../server && go run .
```

---

## ğŸ Known Bugs

- If the backend disconnects temporarily, the frontend doesnâ€™t retry or recover well
- Need a better indicator for GPT loading vs. server unavailability
- Intent parsing is not 100% fool proof.

---

## ğŸŒ± Future Ideas

- Look into costs + latency advantages of combining intent parsing and response into one LLM
- Caching to save on DB lookup

---

## ğŸ³ Docker Setup

This project is also configured to run all services via Docker Compose:

- Neo4j (graph database)
- Ollama (local LLM server)
- Go backend API

### ğŸ› ï¸ Prerequisites

- Docker and Docker Compose.

### ğŸ“ Create `.env`

- Put all variables in project root `.env` file

### âš¡ Load environment variables (Need to do this for Neo4J Auth)

```bash
export $(cat .env | xargs)
```

### ğŸ³ Build and Run

```bash
docker compose up --build
```

This starts Neo4j, Ollama, and your backend.

### ğŸ›‘ Stopping

```bash
docker compose down
```

### âœ… Notes

- The frontend runs separately with Vite.
